{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from kaldi_io import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x.T\n",
    "    x = x - np.max(x, axis=0)\n",
    "    x = np.exp(x)\n",
    "    x /= np.sum(x, axis=0)\n",
    "    return x.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOP computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment\n",
    "load_dotenv('./.env', verbose=True, override=True)\n",
    "#print(os.environ.get('KALDI_ROOT'))\n",
    "#print(os.environ.get('QA_ROOT'))\n",
    "#print(os.environ.get('DATA_ROOT'))\n",
    "#print(os.environ.get('PATH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(os.environ.get('QA_ROOT'), \"s5_mfcc/exp/mono_mfcc_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  os.path.join(MODEL_DIR, 'final.mdl')\n",
    "data = os.path.join(MODEL_DIR, '../../data/train/split8/1')\n",
    "phones_file = os.path.join(MODEL_DIR, 'phones.txt')\n",
    "ali_file = os.path.join(MODEL_DIR, 'ali.1.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mappings between phoneme int code and symbol\n",
    "symb2int = phone_symb2int(phones_file)\n",
    "int2symb = {y: x for x, y in symb2int.items()}\n",
    "\n",
    "# Get mapping for pdf id -> phoneme symbol\n",
    "pdf2symb = pdf2phone(MODEL_DIR)\n",
    "pdf2int = {k:symb2int[v] for k,v in pdf2symb.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "alis = read_ali_from_stdout(model, f'ark:\"gunzip -c {ali_file}|\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute GMM probs for pdf_id(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute gmm probs for each pdf id\n",
    "feats_rspec = f'\"ark,s,cs:apply-cmvn --utt2spk=ark:{data}/utt2spk scp:{data}/cmvn.scp scp:{data}/feats.scp ark:- | add-deltas ark:- ark:- |\"'\n",
    "gmm_likes_command = f'gmm-compute-likes {model} {feats_rspec} ark,t:-'\n",
    "\n",
    "gmm_likes = read_feats_from_stdout(gmm_likes_command)\n",
    "probs = {k:softmax(v) for k,v in gmm_likes.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch from pdf_id to phoneme: sum probs by phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_by_phoneme = {}\n",
    "for reciter, prob in probs.items():\n",
    "    df = pd.DataFrame(data=prob, columns=pdf2int.values())\n",
    "    probs_by_phoneme[reciter] = (\n",
    "        df.groupby(by=df.columns, axis=1)\n",
    "          .sum()\n",
    "          # If you want to return a numpy array just add\n",
    "          #.values\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get probs summary: predicted phoneme (i.e. predicted) VS. alignment phoneme (i.e. real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This seems to be slow.\n",
    "# TODO: Check reciters intersection\n",
    "probs_summary = {}\n",
    "for reciter, prob in probs_by_phoneme.items():\n",
    "    probs_summary[reciter] = []\n",
    "    try:\n",
    "        ali = alis[reciter]\n",
    "    except KeyError:\n",
    "        print(f'Could not find alignment for {reciter}')\n",
    "        continue\n",
    "    for index, row in prob.iterrows():\n",
    "        probs_summary[reciter].append(\n",
    "            [row.max(), row.idxmax(), row[ali[index]], ali[index]]\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}